// ============================================================================
// SERAPHIC - Self-Hosted Seraphim Compiler
// ============================================================================
//
// This is the self-hosted implementation of the Seraphim compiler.
// It is written in Seraphim and can compile itself.
//
// Compilation stages:
//   Stage 0: seraphic.c (C) compiles this file -> seraphic1
//   Stage 1: seraphic1 compiles this file -> seraphic2
//   Stage 2: seraphic2 should be identical to seraphic1 (verification)
//
// Architecture:
//   Source -> Lexer -> Parser -> Checker -> IR Generator -> Backend -> ELF
//
// NIH Compliance: This compiler has ZERO external dependencies.
// ============================================================================

// ============================================================================
// Part 1: Core Types and Constants
// ============================================================================

// VOID-aware integer: bit 63 is VOID flag
struct Vint {
    value: i64,
}

fn vint_new(v: i64) -> Vint {
    return Vint { value: v };
}

fn vint_void() -> Vint {
    return Vint { value: -1 };  // All bits set = VOID
}

fn vint_is_void(v: Vint) -> bool {
    // Check if bit 63 is set (negative in signed representation)
    return v.value < 0;
}

// String type (length-prefixed)
struct Str {
    data: *u8,
    len: i64,
}

fn str_eq(a: Str, b: Str) -> bool {
    if a.len != b.len {
        return false;
    }
    let i: i64 = 0;
    while i < a.len {
        // Compare bytes
        if a.data[i] != b.data[i] {
            return false;
        }
        i = i + 1;
    }
    return true;
}

// Arena allocator for all memory
struct Arena {
    base: *u8,
    size: i64,
    used: i64,
}

fn arena_alloc(arena: *Arena, size: i64, align: i64) -> *u8 {
    // Align up
    let aligned: i64 = (arena.used + align - 1) & ~(align - 1);
    if aligned + size > arena.size {
        return null;
    }
    let ptr: *u8 = arena.base + aligned;
    arena.used = aligned + size;
    return ptr;
}

// ============================================================================
// Syscall Intrinsics (compiler built-ins for self-hosting)
// ============================================================================

// Syscall intrinsic declarations - these are recognized by the compiler
// and emit SYSCALL instructions directly. The first argument is always
// the syscall number, followed by the syscall's arguments.
fn __syscall0(num: i64) -> i64;
fn __syscall1(num: i64, arg1: i64) -> i64;
fn __syscall2(num: i64, arg1: i64, arg2: i64) -> i64;
fn __syscall3(num: i64, arg1: i64, arg2: i64, arg3: i64) -> i64;
fn __syscall4(num: i64, arg1: i64, arg2: i64, arg3: i64, arg4: i64) -> i64;
fn __syscall5(num: i64, arg1: i64, arg2: i64, arg3: i64, arg4: i64, arg5: i64) -> i64;
fn __syscall6(num: i64, arg1: i64, arg2: i64, arg3: i64, arg4: i64, arg5: i64, arg6: i64) -> i64;

// Linux syscall numbers (x86_64)
const SYS_READ: i64 = 0;
const SYS_WRITE: i64 = 1;
const SYS_OPEN: i64 = 2;
const SYS_CLOSE: i64 = 3;
const SYS_LSEEK: i64 = 8;
const SYS_MMAP: i64 = 9;
const SYS_MUNMAP: i64 = 11;
const SYS_EXIT: i64 = 60;

// Open flags
const O_RDONLY: i64 = 0;
const O_WRONLY: i64 = 1;
const O_RDWR: i64 = 2;
const O_CREAT: i64 = 64;
const O_TRUNC: i64 = 512;

// Standard file descriptors
const STDIN_FD: i64 = 0;
const STDOUT_FD: i64 = 1;
const STDERR_FD: i64 = 2;

// ============================================================================
// Syscall Wrapper Functions
// ============================================================================

fn sys_read(fd: i64, buf: *u8, count: i64) -> i64 {
    return __syscall3(SYS_READ, fd, buf as i64, count);
}

fn sys_write(fd: i64, buf: *u8, count: i64) -> i64 {
    return __syscall3(SYS_WRITE, fd, buf as i64, count);
}

fn sys_open(path: *u8, flags: i64, mode: i64) -> i64 {
    return __syscall3(SYS_OPEN, path as i64, flags, mode);
}

fn sys_close(fd: i64) -> i64 {
    return __syscall1(SYS_CLOSE, fd);
}

fn sys_lseek(fd: i64, offset: i64, whence: i64) -> i64 {
    return __syscall3(SYS_LSEEK, fd, offset, whence);
}

fn sys_exit(code: i64) -> i64 {
    return __syscall1(SYS_EXIT, code);
}

fn sys_mmap(addr: i64, len: i64, prot: i64, flags: i64, fd: i64, offset: i64) -> i64 {
    return __syscall6(SYS_MMAP, addr, len, prot, flags, fd, offset);
}

fn sys_munmap(addr: i64, len: i64) -> i64 {
    return __syscall2(SYS_MUNMAP, addr, len);
}

// ============================================================================
// High-level File I/O (using syscalls)
// ============================================================================

fn print(s: Str) {
    sys_write(STDOUT_FD, s.data, s.len);
}

fn println(s: Str) {
    sys_write(STDOUT_FD, s.data, s.len);
    let nl: u8 = 10;  // '\n'
    sys_write(STDOUT_FD, &nl, 1);
}

fn eprint(s: Str) {
    sys_write(STDERR_FD, s.data, s.len);
}

fn eprintln(s: Str) {
    sys_write(STDERR_FD, s.data, s.len);
    let nl: u8 = 10;  // '\n'
    sys_write(STDERR_FD, &nl, 1);
}

// Read entire file into arena-allocated buffer
fn read_file(arena: *Arena, path: *u8) -> Str {
    let fd: i64 = sys_open(path, O_RDONLY, 0);
    if fd < 0 {
        return Str { data: null, len: 0 };
    }

    // Get file size by seeking to end
    let size: i64 = sys_lseek(fd, 0, 2);  // SEEK_END = 2
    if size < 0 {
        sys_close(fd);
        return Str { data: null, len: 0 };
    }

    // Seek back to beginning
    sys_lseek(fd, 0, 0);  // SEEK_SET = 0

    // Allocate buffer
    let buf: *u8 = arena_alloc(arena, size, 1);
    if buf == null {
        sys_close(fd);
        return Str { data: null, len: 0 };
    }

    // Read file contents
    let bytes_read: i64 = sys_read(fd, buf, size);
    sys_close(fd);

    if bytes_read < 0 {
        return Str { data: null, len: 0 };
    }

    return Str { data: buf, len: bytes_read };
}

// Write buffer to file
fn write_file(path: *u8, data: *u8, len: i64) -> bool {
    let fd: i64 = sys_open(path, O_WRONLY | O_CREAT | O_TRUNC, 438);  // 0666 = 438
    if fd < 0 {
        return false;
    }

    let written: i64 = sys_write(fd, data, len);
    sys_close(fd);

    return written == len;
}

// ============================================================================
// Part 2: Source Location
// ============================================================================

struct SourceLoc {
    filename: Str,
    line: i32,
    column: i32,
}

fn loc_new(filename: Str, line: i32, column: i32) -> SourceLoc {
    return SourceLoc {
        filename: filename,
        line: line,
        column: column,
    };
}

// ============================================================================
// Part 3: Token Types
// ============================================================================

enum TokenType {
    // Literals
    TokInt,
    TokFloat,
    TokString,
    TokChar,
    TokIdent,

    // Keywords
    TokFn,
    TokLet,
    TokConst,
    TokStruct,
    TokEnum,
    TokIf,
    TokElse,
    TokMatch,
    TokFor,
    TokWhile,
    TokReturn,
    TokBreak,
    TokContinue,
    TokTrue,
    TokFalse,
    TokNull,
    TokVoid,

    // Operators
    TokPlus,
    TokMinus,
    TokStar,
    TokSlash,
    TokPercent,
    TokAmp,
    TokPipe,
    TokCaret,
    TokTilde,
    TokBang,
    TokEq,
    TokEqEq,
    TokBangEq,
    TokLt,
    TokGt,
    TokLtEq,
    TokGtEq,
    TokAmpAmp,
    TokPipePipe,
    TokLtLt,
    TokGtGt,
    TokArrow,
    TokFatArrow,
    TokDot,
    TokDotDot,
    TokColon,
    TokColonColon,
    TokSemicolon,
    TokComma,
    TokQuestion,

    // Delimiters
    TokLParen,
    TokRParen,
    TokLBrace,
    TokRBrace,
    TokLBracket,
    TokRBracket,

    // Special
    TokEOF,
    TokError,
}

struct Token {
    ty: TokenType,
    loc: SourceLoc,
    text: Str,
    int_value: i64,
    float_value: f64,
}

// ============================================================================
// Part 4: Lexer
// ============================================================================

struct Lexer {
    source: Str,
    pos: i64,
    line: i32,
    column: i32,
    filename: Str,
    arena: *Arena,
    tokens: *Token,
    token_count: i64,
    token_capacity: i64,
}

fn lexer_init(lex: *Lexer, source: Str, filename: Str, arena: *Arena) {
    lex.source = source;
    lex.pos = 0;
    lex.line = 1;
    lex.column = 1;
    lex.filename = filename;
    lex.arena = arena;
    lex.token_count = 0;
    lex.token_capacity = 1024;
    lex.tokens = arena_alloc(arena, 1024 * 64, 8) as *Token;  // sizeof(Token) ~= 64
}

fn lexer_at_end(lex: *Lexer) -> bool {
    return lex.pos >= lex.source.len;
}

fn lexer_peek(lex: *Lexer) -> u8 {
    if lexer_at_end(lex) {
        return 0;
    }
    return lex.source.data[lex.pos];
}

fn lexer_peek_next(lex: *Lexer) -> u8 {
    if lex.pos + 1 >= lex.source.len {
        return 0;
    }
    return lex.source.data[lex.pos + 1];
}

fn lexer_advance(lex: *Lexer) -> u8 {
    if lexer_at_end(lex) {
        return 0;
    }
    let c: u8 = lex.source.data[lex.pos];
    lex.pos = lex.pos + 1;
    if c == 10 {  // '\n'
        lex.line = lex.line + 1;
        lex.column = 1;
    } else {
        lex.column = lex.column + 1;
    }
    return c;
}

fn is_digit(c: u8) -> bool {
    return c >= 48 && c <= 57;  // '0' to '9'
}

fn is_alpha(c: u8) -> bool {
    return (c >= 65 && c <= 90) || (c >= 97 && c <= 122) || c == 95;  // A-Z, a-z, _
}

fn is_alnum(c: u8) -> bool {
    return is_alpha(c) || is_digit(c);
}

fn is_whitespace(c: u8) -> bool {
    return c == 32 || c == 9 || c == 10 || c == 13;  // space, tab, newline, carriage return
}

fn lexer_skip_whitespace(lex: *Lexer) {
    while !lexer_at_end(lex) {
        let c: u8 = lexer_peek(lex);
        if is_whitespace(c) {
            lexer_advance(lex);
        } else if c == 47 && lexer_peek_next(lex) == 47 {  // '//'
            // Skip line comment
            while !lexer_at_end(lex) && lexer_peek(lex) != 10 {
                lexer_advance(lex);
            }
        } else if c == 47 && lexer_peek_next(lex) == 42 {  // '/*'
            // Skip block comment
            lexer_advance(lex);
            lexer_advance(lex);
            while !lexer_at_end(lex) {
                if lexer_peek(lex) == 42 && lexer_peek_next(lex) == 47 {
                    lexer_advance(lex);
                    lexer_advance(lex);
                    break;
                }
                lexer_advance(lex);
            }
        } else {
            break;
        }
    }
}

fn lexer_make_token(lex: *Lexer, ty: TokenType, start: i64, start_line: i32, start_col: i32) -> Token {
    let tok: Token;
    tok.ty = ty;
    tok.loc = loc_new(lex.filename, start_line, start_col);
    tok.text.data = lex.source.data + start;
    tok.text.len = lex.pos - start;
    tok.int_value = 0;
    tok.float_value = 0.0;
    return tok;
}

fn lexer_scan_number(lex: *Lexer) -> Token {
    let start: i64 = lex.pos;
    let start_line: i32 = lex.line;
    let start_col: i32 = lex.column;

    // Scan integer part
    while is_digit(lexer_peek(lex)) {
        lexer_advance(lex);
    }

    // Check for decimal point
    let is_float: bool = false;
    if lexer_peek(lex) == 46 && is_digit(lexer_peek_next(lex)) {  // '.'
        is_float = true;
        lexer_advance(lex);
        while is_digit(lexer_peek(lex)) {
            lexer_advance(lex);
        }
    }

    let tok: Token = lexer_make_token(lex, TokInt, start, start_line, start_col);

    // Parse the number value
    if is_float {
        tok.ty = TokFloat;
        // Parse float value: integer part + fractional part
        let int_part: f64 = 0.0;
        let frac_part: f64 = 0.0;
        let frac_div: f64 = 1.0;
        let past_dot: bool = false;
        let i: i64 = start;
        while i < lex.pos {
            let c: u8 = lex.source.data[i];
            if c == 46 {  // '.'
                past_dot = true;
            } else {
                let digit: f64 = (c - 48) as f64;
                if past_dot {
                    frac_div = frac_div * 10.0;
                    frac_part = frac_part + digit / frac_div;
                } else {
                    int_part = int_part * 10.0 + digit;
                }
            }
            i = i + 1;
        }
        tok.float_value = int_part + frac_part;
    } else {
        // Parse integer value
        let val: i64 = 0;
        let i: i64 = start;
        while i < lex.pos {
            val = val * 10 + (lex.source.data[i] - 48) as i64;
            i = i + 1;
        }
        tok.int_value = val;
    }

    return tok;
}

fn lexer_scan_identifier(lex: *Lexer) -> Token {
    let start: i64 = lex.pos;
    let start_line: i32 = lex.line;
    let start_col: i32 = lex.column;

    while is_alnum(lexer_peek(lex)) {
        lexer_advance(lex);
    }

    let tok: Token = lexer_make_token(lex, TokIdent, start, start_line, start_col);

    // Check for keywords
    // fn, let, const, struct, enum, if, else, match, for, while, return, break, continue, true, false, null, void
    if tok.text.len == 2 {
        if tok.text.data[0] == 102 && tok.text.data[1] == 110 {  // "fn"
            tok.ty = TokFn;
        } else if tok.text.data[0] == 105 && tok.text.data[1] == 102 {  // "if"
            tok.ty = TokIf;
        }
    } else if tok.text.len == 3 {
        if tok.text.data[0] == 108 && tok.text.data[1] == 101 && tok.text.data[2] == 116 {  // "let"
            tok.ty = TokLet;
        } else if tok.text.data[0] == 102 && tok.text.data[1] == 111 && tok.text.data[2] == 114 {  // "for"
            tok.ty = TokFor;
        }
    } else if tok.text.len == 4 {
        if tok.text.data[0] == 101 && tok.text.data[1] == 108 && tok.text.data[2] == 115 && tok.text.data[3] == 101 {  // "else"
            tok.ty = TokElse;
        } else if tok.text.data[0] == 116 && tok.text.data[1] == 114 && tok.text.data[2] == 117 && tok.text.data[3] == 101 {  // "true"
            tok.ty = TokTrue;
        } else if tok.text.data[0] == 110 && tok.text.data[1] == 117 && tok.text.data[2] == 108 && tok.text.data[3] == 108 {  // "null"
            tok.ty = TokNull;
        } else if tok.text.data[0] == 118 && tok.text.data[1] == 111 && tok.text.data[2] == 105 && tok.text.data[3] == 100 {  // "void"
            tok.ty = TokVoid;
        } else if tok.text.data[0] == 101 && tok.text.data[1] == 110 && tok.text.data[2] == 117 && tok.text.data[3] == 109 {  // "enum"
            tok.ty = TokEnum;
        }
    } else if tok.text.len == 5 {
        if tok.text.data[0] == 119 && tok.text.data[1] == 104 && tok.text.data[2] == 105 && tok.text.data[3] == 108 && tok.text.data[4] == 101 {  // "while"
            tok.ty = TokWhile;
        } else if tok.text.data[0] == 109 && tok.text.data[1] == 97 && tok.text.data[2] == 116 && tok.text.data[3] == 99 && tok.text.data[4] == 104 {  // "match"
            tok.ty = TokMatch;
        } else if tok.text.data[0] == 99 && tok.text.data[1] == 111 && tok.text.data[2] == 110 && tok.text.data[3] == 115 && tok.text.data[4] == 116 {  // "const"
            tok.ty = TokConst;
        } else if tok.text.data[0] == 102 && tok.text.data[1] == 97 && tok.text.data[2] == 108 && tok.text.data[3] == 115 && tok.text.data[4] == 101 {  // "false"
            tok.ty = TokFalse;
        } else if tok.text.data[0] == 98 && tok.text.data[1] == 114 && tok.text.data[2] == 101 && tok.text.data[3] == 97 && tok.text.data[4] == 107 {  // "break"
            tok.ty = TokBreak;
        }
    } else if tok.text.len == 6 {
        if tok.text.data[0] == 115 && tok.text.data[1] == 116 && tok.text.data[2] == 114 && tok.text.data[3] == 117 && tok.text.data[4] == 99 && tok.text.data[5] == 116 {  // "struct"
            tok.ty = TokStruct;
        } else if tok.text.data[0] == 114 && tok.text.data[1] == 101 && tok.text.data[2] == 116 && tok.text.data[3] == 117 && tok.text.data[4] == 114 && tok.text.data[5] == 110 {  // "return"
            tok.ty = TokReturn;
        }
    } else if tok.text.len == 8 {
        if tok.text.data[0] == 99 && tok.text.data[1] == 111 && tok.text.data[2] == 110 && tok.text.data[3] == 116 && tok.text.data[4] == 105 && tok.text.data[5] == 110 && tok.text.data[6] == 117 && tok.text.data[7] == 101 {  // "continue"
            tok.ty = TokContinue;
        }
    }

    return tok;
}

fn lexer_scan_string(lex: *Lexer) -> Token {
    let start: i64 = lex.pos;
    let start_line: i32 = lex.line;
    let start_col: i32 = lex.column;

    lexer_advance(lex);  // Opening quote

    while !lexer_at_end(lex) && lexer_peek(lex) != 34 {  // '"'
        if lexer_peek(lex) == 92 {  // '\'
            lexer_advance(lex);  // Skip escape char
        }
        lexer_advance(lex);
    }

    if lexer_at_end(lex) {
        return lexer_make_token(lex, TokError, start, start_line, start_col);
    }

    lexer_advance(lex);  // Closing quote

    return lexer_make_token(lex, TokString, start, start_line, start_col);
}

fn lexer_scan_token(lex: *Lexer) -> Token {
    lexer_skip_whitespace(lex);

    if lexer_at_end(lex) {
        return lexer_make_token(lex, TokEOF, lex.pos, lex.line, lex.column);
    }

    let start: i64 = lex.pos;
    let start_line: i32 = lex.line;
    let start_col: i32 = lex.column;

    let c: u8 = lexer_advance(lex);

    // Numbers
    if is_digit(c) {
        lex.pos = lex.pos - 1;
        lex.column = lex.column - 1;
        return lexer_scan_number(lex);
    }

    // Identifiers and keywords
    if is_alpha(c) {
        lex.pos = lex.pos - 1;
        lex.column = lex.column - 1;
        return lexer_scan_identifier(lex);
    }

    // Strings
    if c == 34 {  // '"'
        lex.pos = lex.pos - 1;
        lex.column = lex.column - 1;
        return lexer_scan_string(lex);
    }

    // Single-character tokens
    match c {
        40 => { return lexer_make_token(lex, TokLParen, start, start_line, start_col); }    // '('
        41 => { return lexer_make_token(lex, TokRParen, start, start_line, start_col); }    // ')'
        123 => { return lexer_make_token(lex, TokLBrace, start, start_line, start_col); }   // '{'
        125 => { return lexer_make_token(lex, TokRBrace, start, start_line, start_col); }   // '}'
        91 => { return lexer_make_token(lex, TokLBracket, start, start_line, start_col); }  // '['
        93 => { return lexer_make_token(lex, TokRBracket, start, start_line, start_col); }  // ']'
        59 => { return lexer_make_token(lex, TokSemicolon, start, start_line, start_col); } // ';'
        44 => { return lexer_make_token(lex, TokComma, start, start_line, start_col); }     // ','
        126 => { return lexer_make_token(lex, TokTilde, start, start_line, start_col); }    // '~'
        63 => { return lexer_make_token(lex, TokQuestion, start, start_line, start_col); }  // '?'
        _ => {}
    }

    // Two-character tokens
    let next: u8 = lexer_peek(lex);

    if c == 43 {  // '+'
        return lexer_make_token(lex, TokPlus, start, start_line, start_col);
    }
    if c == 45 {  // '-'
        if next == 62 {  // '>'
            lexer_advance(lex);
            return lexer_make_token(lex, TokArrow, start, start_line, start_col);
        }
        return lexer_make_token(lex, TokMinus, start, start_line, start_col);
    }
    if c == 42 {  // '*'
        return lexer_make_token(lex, TokStar, start, start_line, start_col);
    }
    if c == 47 {  // '/'
        return lexer_make_token(lex, TokSlash, start, start_line, start_col);
    }
    if c == 37 {  // '%'
        return lexer_make_token(lex, TokPercent, start, start_line, start_col);
    }
    if c == 38 {  // '&'
        if next == 38 {  // '&'
            lexer_advance(lex);
            return lexer_make_token(lex, TokAmpAmp, start, start_line, start_col);
        }
        return lexer_make_token(lex, TokAmp, start, start_line, start_col);
    }
    if c == 124 {  // '|'
        if next == 124 {  // '|'
            lexer_advance(lex);
            return lexer_make_token(lex, TokPipePipe, start, start_line, start_col);
        }
        return lexer_make_token(lex, TokPipe, start, start_line, start_col);
    }
    if c == 94 {  // '^'
        return lexer_make_token(lex, TokCaret, start, start_line, start_col);
    }
    if c == 33 {  // '!'
        if next == 61 {  // '='
            lexer_advance(lex);
            return lexer_make_token(lex, TokBangEq, start, start_line, start_col);
        }
        return lexer_make_token(lex, TokBang, start, start_line, start_col);
    }
    if c == 61 {  // '='
        if next == 61 {  // '='
            lexer_advance(lex);
            return lexer_make_token(lex, TokEqEq, start, start_line, start_col);
        }
        if next == 62 {  // '>'
            lexer_advance(lex);
            return lexer_make_token(lex, TokFatArrow, start, start_line, start_col);
        }
        return lexer_make_token(lex, TokEq, start, start_line, start_col);
    }
    if c == 60 {  // '<'
        if next == 61 {  // '='
            lexer_advance(lex);
            return lexer_make_token(lex, TokLtEq, start, start_line, start_col);
        }
        if next == 60 {  // '<'
            lexer_advance(lex);
            return lexer_make_token(lex, TokLtLt, start, start_line, start_col);
        }
        return lexer_make_token(lex, TokLt, start, start_line, start_col);
    }
    if c == 62 {  // '>'
        if next == 61 {  // '='
            lexer_advance(lex);
            return lexer_make_token(lex, TokGtEq, start, start_line, start_col);
        }
        if next == 62 {  // '>'
            lexer_advance(lex);
            return lexer_make_token(lex, TokGtGt, start, start_line, start_col);
        }
        return lexer_make_token(lex, TokGt, start, start_line, start_col);
    }
    if c == 46 {  // '.'
        if next == 46 {  // '.'
            lexer_advance(lex);
            return lexer_make_token(lex, TokDotDot, start, start_line, start_col);
        }
        return lexer_make_token(lex, TokDot, start, start_line, start_col);
    }
    if c == 58 {  // ':'
        if next == 58 {  // ':'
            lexer_advance(lex);
            return lexer_make_token(lex, TokColonColon, start, start_line, start_col);
        }
        return lexer_make_token(lex, TokColon, start, start_line, start_col);
    }

    // Unknown character
    return lexer_make_token(lex, TokError, start, start_line, start_col);
}

fn lexer_tokenize(lex: *Lexer) -> bool {
    while !lexer_at_end(lex) {
        let tok: Token = lexer_scan_token(lex);

        if lex.token_count >= lex.token_capacity {
            return false;  // Out of space
        }

        lex.tokens[lex.token_count] = tok;
        lex.token_count = lex.token_count + 1;

        if tok.ty == TokEOF || tok.ty == TokError {
            break;
        }
    }
    return true;
}

// ============================================================================
// Part 5: AST Node Types
// ============================================================================

enum AstKind {
    // Module level
    AstModule,
    AstFnDecl,
    AstStructDecl,
    AstEnumDecl,
    AstFieldDecl,
    AstVariantDecl,

    // Statements
    AstLetStmt,
    AstExprStmt,
    AstReturnStmt,
    AstBreakStmt,
    AstContinueStmt,
    AstBlock,

    // Expressions
    AstIntLit,
    AstFloatLit,
    AstStringLit,
    AstBoolLit,
    AstNullLit,
    AstIdent,
    AstBinOp,
    AstUnaryOp,
    AstCall,
    AstIndex,
    AstField,
    AstIf,
    AstMatch,
    AstFor,
    AstWhile,
    AstStructInit,
    AstArrayInit,
    AstCast,

    // Types
    AstTypeIdent,
    AstTypePtr,
    AstTypeArray,
    AstTypeFn,
}

struct AstNode {
    kind: AstKind,
    loc: SourceLoc,
    next: *AstNode,

    // Union-like fields (we use the relevant ones based on kind)
    name: Str,           // For declarations and identifiers
    int_value: i64,      // For int literals
    float_value: f64,    // For float literals
    bool_value: bool,    // For bool literals
    string_value: Str,   // For string literals

    // Tree structure
    left: *AstNode,      // Binary op left, if condition, etc.
    right: *AstNode,     // Binary op right, if then branch, etc.
    third: *AstNode,     // If else branch, etc.
    children: *AstNode,  // List of children (function body, struct fields, etc.)

    // Type information
    type_node: *AstNode,

    // Operator for binary/unary ops
    op: TokenType,
}

// ============================================================================
// Part 6: Parser
// ============================================================================

struct Parser {
    lex: *Lexer,
    pos: i64,
    arena: *Arena,
    error_count: i32,
}

fn parser_init(p: *Parser, lex: *Lexer, arena: *Arena) {
    p.lex = lex;
    p.pos = 0;
    p.arena = arena;
    p.error_count = 0;
}

fn parser_current(p: *Parser) -> *Token {
    if p.pos >= p.lex.token_count {
        return null;
    }
    return &p.lex.tokens[p.pos];
}

fn parser_at_end(p: *Parser) -> bool {
    let tok: *Token = parser_current(p);
    if tok == null {
        return true;
    }
    return tok.ty == TokEOF;
}

fn parser_check(p: *Parser, ty: TokenType) -> bool {
    let tok: *Token = parser_current(p);
    if tok == null {
        return false;
    }
    return tok.ty == ty;
}

fn parser_advance(p: *Parser) -> *Token {
    if parser_at_end(p) {
        return null;
    }
    let tok: *Token = parser_current(p);
    p.pos = p.pos + 1;
    return tok;
}

fn parser_match(p: *Parser, ty: TokenType) -> bool {
    if parser_check(p, ty) {
        parser_advance(p);
        return true;
    }
    return false;
}

fn parser_consume(p: *Parser, ty: TokenType) -> *Token {
    if parser_check(p, ty) {
        return parser_advance(p);
    }
    p.error_count = p.error_count + 1;
    return null;
}

fn parser_alloc_node(p: *Parser, kind: AstKind) -> *AstNode {
    let node: *AstNode = arena_alloc(p.arena, 128, 8) as *AstNode;  // sizeof(AstNode) ~= 128
    if node == null {
        return null;
    }
    // Zero initialize
    node.kind = kind;
    node.next = null;
    node.left = null;
    node.right = null;
    node.third = null;
    node.children = null;
    node.type_node = null;
    return node;
}

// Forward declarations
fn parse_expr(p: *Parser) -> *AstNode;
fn parse_stmt(p: *Parser) -> *AstNode;
fn parse_type(p: *Parser) -> *AstNode;
fn parse_block(p: *Parser) -> *AstNode;

fn parse_primary(p: *Parser) -> *AstNode {
    let tok: *Token = parser_current(p);
    if tok == null {
        return null;
    }

    match tok.ty {
        TokInt => {
            parser_advance(p);
            let node: *AstNode = parser_alloc_node(p, AstIntLit);
            node.loc = tok.loc;
            node.int_value = tok.int_value;
            return node;
        }
        TokFloat => {
            parser_advance(p);
            let node: *AstNode = parser_alloc_node(p, AstFloatLit);
            node.loc = tok.loc;
            node.float_value = tok.float_value;
            return node;
        }
        TokString => {
            parser_advance(p);
            let node: *AstNode = parser_alloc_node(p, AstStringLit);
            node.loc = tok.loc;
            node.string_value = tok.text;
            return node;
        }
        TokTrue => {
            parser_advance(p);
            let node: *AstNode = parser_alloc_node(p, AstBoolLit);
            node.loc = tok.loc;
            node.bool_value = true;
            return node;
        }
        TokFalse => {
            parser_advance(p);
            let node: *AstNode = parser_alloc_node(p, AstBoolLit);
            node.loc = tok.loc;
            node.bool_value = false;
            return node;
        }
        TokNull => {
            parser_advance(p);
            let node: *AstNode = parser_alloc_node(p, AstNullLit);
            node.loc = tok.loc;
            return node;
        }
        TokIdent => {
            parser_advance(p);
            let node: *AstNode = parser_alloc_node(p, AstIdent);
            node.loc = tok.loc;
            node.name = tok.text;
            return node;
        }
        TokLParen => {
            parser_advance(p);
            let expr: *AstNode = parse_expr(p);
            parser_consume(p, TokRParen);
            return expr;
        }
        TokIf => {
            return parse_if_expr(p);
        }
        TokMatch => {
            return parse_match_expr(p);
        }
        _ => {
            p.error_count = p.error_count + 1;
            return null;
        }
    }
}

fn get_precedence(ty: TokenType) -> i32 {
    match ty {
        TokPipePipe => { return 1; }
        TokAmpAmp => { return 2; }
        TokPipe => { return 3; }
        TokCaret => { return 4; }
        TokAmp => { return 5; }
        TokEqEq => { return 6; }
        TokBangEq => { return 6; }
        TokLt => { return 7; }
        TokGt => { return 7; }
        TokLtEq => { return 7; }
        TokGtEq => { return 7; }
        TokLtLt => { return 8; }
        TokGtGt => { return 8; }
        TokPlus => { return 9; }
        TokMinus => { return 9; }
        TokStar => { return 10; }
        TokSlash => { return 10; }
        TokPercent => { return 10; }
        _ => { return 0; }
    }
}

fn parse_expr_prec(p: *Parser, min_prec: i32) -> *AstNode {
    let left: *AstNode = parse_primary(p);
    if left == null {
        return null;
    }

    while true {
        let tok: *Token = parser_current(p);
        if tok == null {
            break;
        }

        let prec: i32 = get_precedence(tok.ty);
        if prec <= min_prec {
            break;
        }

        let op: TokenType = tok.ty;
        parser_advance(p);

        let right: *AstNode = parse_expr_prec(p, prec);
        if right == null {
            return null;
        }

        let bin: *AstNode = parser_alloc_node(p, AstBinOp);
        bin.loc = tok.loc;
        bin.op = op;
        bin.left = left;
        bin.right = right;
        left = bin;
    }

    // Handle postfix operations (calls, indexing, field access)
    while true {
        let tok: *Token = parser_current(p);
        if tok == null {
            break;
        }

        if tok.ty == TokLParen {
            // Function call
            parser_advance(p);
            let call: *AstNode = parser_alloc_node(p, AstCall);
            call.loc = tok.loc;
            call.left = left;

            // Parse arguments
            let first_arg: *AstNode = null;
            let last_arg: *AstNode = null;

            if !parser_check(p, TokRParen) {
                let arg: *AstNode = parse_expr(p);
                if first_arg == null {
                    first_arg = arg;
                } else {
                    last_arg.next = arg;
                }
                last_arg = arg;

                while parser_match(p, TokComma) {
                    arg = parse_expr(p);
                    if last_arg != null {
                        last_arg.next = arg;
                    }
                    last_arg = arg;
                }
            }

            call.children = first_arg;
            parser_consume(p, TokRParen);
            left = call;
        } else if tok.ty == TokLBracket {
            // Array indexing
            parser_advance(p);
            let idx: *AstNode = parser_alloc_node(p, AstIndex);
            idx.loc = tok.loc;
            idx.left = left;
            idx.right = parse_expr(p);
            parser_consume(p, TokRBracket);
            left = idx;
        } else if tok.ty == TokDot {
            // Field access
            parser_advance(p);
            let field: *AstNode = parser_alloc_node(p, AstField);
            field.loc = tok.loc;
            field.left = left;
            let name_tok: *Token = parser_consume(p, TokIdent);
            if name_tok != null {
                field.name = name_tok.text;
            }
            left = field;
        } else {
            break;
        }
    }

    return left;
}

fn parse_expr(p: *Parser) -> *AstNode {
    return parse_expr_prec(p, 0);
}

fn parse_if_expr(p: *Parser) -> *AstNode {
    let tok: *Token = parser_consume(p, TokIf);
    let node: *AstNode = parser_alloc_node(p, AstIf);
    node.loc = tok.loc;

    node.left = parse_expr(p);  // condition
    node.right = parse_block(p);  // then branch

    if parser_match(p, TokElse) {
        if parser_check(p, TokIf) {
            node.third = parse_if_expr(p);
        } else {
            node.third = parse_block(p);
        }
    }

    return node;
}

fn parse_match_expr(p: *Parser) -> *AstNode {
    let tok: *Token = parser_consume(p, TokMatch);
    let node: *AstNode = parser_alloc_node(p, AstMatch);
    node.loc = tok.loc;

    node.left = parse_expr(p);  // scrutinee

    parser_consume(p, TokLBrace);

    // Parse match arms
    let first_arm: *AstNode = null;
    let last_arm: *AstNode = null;

    while !parser_check(p, TokRBrace) && !parser_at_end(p) {
        // Pattern => expr
        let pattern: *AstNode = parse_expr(p);
        parser_consume(p, TokFatArrow);

        let body: *AstNode;
        if parser_check(p, TokLBrace) {
            body = parse_block(p);
        } else {
            body = parse_expr(p);
        }

        // Create arm node
        let arm: *AstNode = parser_alloc_node(p, AstBinOp);  // Reuse binop for arm
        arm.left = pattern;
        arm.right = body;

        if first_arm == null {
            first_arm = arm;
        } else {
            last_arm.next = arm;
        }
        last_arm = arm;

        parser_match(p, TokComma);
    }

    node.children = first_arm;
    parser_consume(p, TokRBrace);

    return node;
}

fn parse_type(p: *Parser) -> *AstNode {
    let tok: *Token = parser_current(p);

    if parser_match(p, TokStar) {
        // Pointer type
        let ptr: *AstNode = parser_alloc_node(p, AstTypePtr);
        ptr.loc = tok.loc;
        ptr.left = parse_type(p);
        return ptr;
    }

    if parser_match(p, TokLBracket) {
        // Array type
        let arr: *AstNode = parser_alloc_node(p, AstTypeArray);
        arr.loc = tok.loc;
        arr.left = parse_type(p);
        parser_consume(p, TokRBracket);
        return arr;
    }

    if parser_check(p, TokIdent) {
        parser_advance(p);
        let type_node: *AstNode = parser_alloc_node(p, AstTypeIdent);
        type_node.loc = tok.loc;
        type_node.name = tok.text;
        return type_node;
    }

    p.error_count = p.error_count + 1;
    return null;
}

fn parse_let_stmt(p: *Parser) -> *AstNode {
    let tok: *Token = parser_consume(p, TokLet);
    let node: *AstNode = parser_alloc_node(p, AstLetStmt);
    node.loc = tok.loc;

    let name_tok: *Token = parser_consume(p, TokIdent);
    if name_tok != null {
        node.name = name_tok.text;
    }

    if parser_match(p, TokColon) {
        node.type_node = parse_type(p);
    }

    if parser_match(p, TokEq) {
        node.left = parse_expr(p);
    }

    parser_consume(p, TokSemicolon);
    return node;
}

fn parse_return_stmt(p: *Parser) -> *AstNode {
    let tok: *Token = parser_consume(p, TokReturn);
    let node: *AstNode = parser_alloc_node(p, AstReturnStmt);
    node.loc = tok.loc;

    if !parser_check(p, TokSemicolon) {
        node.left = parse_expr(p);
    }

    parser_consume(p, TokSemicolon);
    return node;
}

fn parse_stmt(p: *Parser) -> *AstNode {
    if parser_check(p, TokLet) {
        return parse_let_stmt(p);
    }
    if parser_check(p, TokReturn) {
        return parse_return_stmt(p);
    }
    if parser_check(p, TokBreak) {
        let tok: *Token = parser_advance(p);
        let node: *AstNode = parser_alloc_node(p, AstBreakStmt);
        node.loc = tok.loc;
        parser_consume(p, TokSemicolon);
        return node;
    }
    if parser_check(p, TokContinue) {
        let tok: *Token = parser_advance(p);
        let node: *AstNode = parser_alloc_node(p, AstContinueStmt);
        node.loc = tok.loc;
        parser_consume(p, TokSemicolon);
        return node;
    }
    if parser_check(p, TokIf) {
        return parse_if_expr(p);
    }
    if parser_check(p, TokWhile) {
        return parse_while_stmt(p);
    }
    if parser_check(p, TokFor) {
        return parse_for_stmt(p);
    }
    if parser_check(p, TokLBrace) {
        return parse_block(p);
    }

    // Expression statement
    let node: *AstNode = parser_alloc_node(p, AstExprStmt);
    node.loc = parser_current(p).loc;
    node.left = parse_expr(p);
    parser_consume(p, TokSemicolon);
    return node;
}

fn parse_block(p: *Parser) -> *AstNode {
    let tok: *Token = parser_consume(p, TokLBrace);
    let node: *AstNode = parser_alloc_node(p, AstBlock);
    node.loc = tok.loc;

    let first: *AstNode = null;
    let last: *AstNode = null;

    while !parser_check(p, TokRBrace) && !parser_at_end(p) {
        let stmt: *AstNode = parse_stmt(p);
        if stmt != null {
            if first == null {
                first = stmt;
            } else {
                last.next = stmt;
            }
            last = stmt;
        }
    }

    node.children = first;
    parser_consume(p, TokRBrace);
    return node;
}

fn parse_while_stmt(p: *Parser) -> *AstNode {
    let tok: *Token = parser_consume(p, TokWhile);
    let node: *AstNode = parser_alloc_node(p, AstWhile);
    node.loc = tok.loc;
    node.left = parse_expr(p);  // condition
    node.right = parse_block(p);  // body
    return node;
}

fn parse_for_stmt(p: *Parser) -> *AstNode {
    let tok: *Token = parser_consume(p, TokFor);
    let node: *AstNode = parser_alloc_node(p, AstFor);
    node.loc = tok.loc;

    // Parse loop variable
    let var_tok: *Token = parser_consume(p, TokIdent);
    if var_tok != null {
        node.name = var_tok.text;
    }

    // "in" keyword (we'll use TokIdent for now)
    parser_consume(p, TokIdent);  // "in"

    node.left = parse_expr(p);  // iterator expression
    node.right = parse_block(p);  // body

    return node;
}

fn parse_fn_decl(p: *Parser) -> *AstNode {
    let tok: *Token = parser_consume(p, TokFn);
    let node: *AstNode = parser_alloc_node(p, AstFnDecl);
    node.loc = tok.loc;

    // Function name
    let name_tok: *Token = parser_consume(p, TokIdent);
    if name_tok != null {
        node.name = name_tok.text;
    }

    // Parameters
    parser_consume(p, TokLParen);

    let first_param: *AstNode = null;
    let last_param: *AstNode = null;

    while !parser_check(p, TokRParen) && !parser_at_end(p) {
        let param: *AstNode = parser_alloc_node(p, AstFieldDecl);

        let param_name: *Token = parser_consume(p, TokIdent);
        if param_name != null {
            param.name = param_name.text;
        }

        parser_consume(p, TokColon);
        param.type_node = parse_type(p);

        if first_param == null {
            first_param = param;
        } else {
            last_param.next = param;
        }
        last_param = param;

        if !parser_check(p, TokRParen) {
            parser_consume(p, TokComma);
        }
    }

    node.left = first_param;  // parameters
    parser_consume(p, TokRParen);

    // Return type
    if parser_match(p, TokArrow) {
        node.type_node = parse_type(p);
    }

    // Body
    node.right = parse_block(p);

    return node;
}

fn parse_struct_decl(p: *Parser) -> *AstNode {
    let tok: *Token = parser_consume(p, TokStruct);
    let node: *AstNode = parser_alloc_node(p, AstStructDecl);
    node.loc = tok.loc;

    let name_tok: *Token = parser_consume(p, TokIdent);
    if name_tok != null {
        node.name = name_tok.text;
    }

    parser_consume(p, TokLBrace);

    let first_field: *AstNode = null;
    let last_field: *AstNode = null;

    while !parser_check(p, TokRBrace) && !parser_at_end(p) {
        let field: *AstNode = parser_alloc_node(p, AstFieldDecl);

        let field_name: *Token = parser_consume(p, TokIdent);
        if field_name != null {
            field.name = field_name.text;
        }

        parser_consume(p, TokColon);
        field.type_node = parse_type(p);

        if first_field == null {
            first_field = field;
        } else {
            last_field.next = field;
        }
        last_field = field;

        parser_consume(p, TokComma);
    }

    node.children = first_field;
    parser_consume(p, TokRBrace);

    return node;
}

fn parse_enum_decl(p: *Parser) -> *AstNode {
    let tok: *Token = parser_consume(p, TokEnum);
    let node: *AstNode = parser_alloc_node(p, AstEnumDecl);
    node.loc = tok.loc;

    let name_tok: *Token = parser_consume(p, TokIdent);
    if name_tok != null {
        node.name = name_tok.text;
    }

    parser_consume(p, TokLBrace);

    let first_var: *AstNode = null;
    let last_var: *AstNode = null;

    while !parser_check(p, TokRBrace) && !parser_at_end(p) {
        let var: *AstNode = parser_alloc_node(p, AstVariantDecl);

        let var_name: *Token = parser_consume(p, TokIdent);
        if var_name != null {
            var.name = var_name.text;
        }

        if first_var == null {
            first_var = var;
        } else {
            last_var.next = var;
        }
        last_var = var;

        parser_match(p, TokComma);
    }

    node.children = first_var;
    parser_consume(p, TokRBrace);

    return node;
}

fn parse_module(p: *Parser) -> *AstNode {
    let node: *AstNode = parser_alloc_node(p, AstModule);

    let first: *AstNode = null;
    let last: *AstNode = null;

    while !parser_at_end(p) {
        let decl: *AstNode = null;

        if parser_check(p, TokFn) {
            decl = parse_fn_decl(p);
        } else if parser_check(p, TokStruct) {
            decl = parse_struct_decl(p);
        } else if parser_check(p, TokEnum) {
            decl = parse_enum_decl(p);
        } else {
            // Skip unknown token
            parser_advance(p);
            continue;
        }

        if decl != null {
            if first == null {
                first = decl;
            } else {
                last.next = decl;
            }
            last = decl;
        }
    }

    node.children = first;
    return node;
}

// ============================================================================
// Part 7: Type System
// ============================================================================

enum TypeKind {
    TyVoid,
    TyBool,
    TyI8,
    TyI16,
    TyI32,
    TyI64,
    TyU8,
    TyU16,
    TyU32,
    TyU64,
    TyF32,
    TyF64,
    TyPtr,
    TyArray,
    TyStruct,
    TyFunc,
}

struct Type {
    kind: TypeKind,
    size: i64,
    align: i64,
    // For pointers
    pointee: *Type,
    // For arrays
    elem_type: *Type,
    elem_count: i64,
    // For structs
    name: Str,
    fields: *TypeField,
    field_count: i64,
    // For functions
    ret_type: *Type,
    param_types: **Type,
    param_count: i64,
}

struct TypeField {
    name: Str,
    ty: *Type,
    offset: i64,
    next: *TypeField,
}

struct TypeContext {
    arena: *Arena,
    types: *Type,
    type_count: i64,
    // Named type lookup
    struct_names: *Str,
    struct_types: **Type,
    struct_count: i64,
}

fn type_void(ctx: *TypeContext) -> *Type {
    let t: *Type = arena_alloc(ctx.arena, 64, 8);
    t.kind = TyVoid;
    t.size = 0;
    t.align = 1;
    return t;
}

fn type_i64(ctx: *TypeContext) -> *Type {
    let t: *Type = arena_alloc(ctx.arena, 64, 8);
    t.kind = TyI64;
    t.size = 8;
    t.align = 8;
    return t;
}

fn type_i32(ctx: *TypeContext) -> *Type {
    let t: *Type = arena_alloc(ctx.arena, 64, 8);
    t.kind = TyI32;
    t.size = 4;
    t.align = 4;
    return t;
}

fn type_bool(ctx: *TypeContext) -> *Type {
    let t: *Type = arena_alloc(ctx.arena, 64, 8);
    t.kind = TyBool;
    t.size = 1;
    t.align = 1;
    return t;
}

fn type_ptr(ctx: *TypeContext, pointee: *Type) -> *Type {
    let t: *Type = arena_alloc(ctx.arena, 64, 8);
    t.kind = TyPtr;
    t.size = 8;
    t.align = 8;
    t.pointee = pointee;
    return t;
}

fn type_size(t: *Type) -> i64 {
    if t == null {
        return 8;
    }
    return t.size;
}

// ============================================================================
// Part 8: Type Checker
// ============================================================================

// Symbol must be defined before Checker since Checker references *Symbol
struct Symbol {
    name: Str,
    ty: *Type,
    scope: i64,
    next: *Symbol,
}

struct Checker {
    arena: *Arena,
    type_ctx: *TypeContext,
    errors: i64,
    // Symbol table
    symbols: *Symbol,
    symbol_count: i64,
    scope_depth: i64,
}

fn checker_init(c: *Checker, arena: *Arena, type_ctx: *TypeContext) {
    c.arena = arena;
    c.type_ctx = type_ctx;
    c.errors = 0;
    c.symbols = null;
    c.symbol_count = 0;
    c.scope_depth = 0;
}

fn checker_push_scope(c: *Checker) {
    c.scope_depth = c.scope_depth + 1;
}

fn checker_pop_scope(c: *Checker) {
    // Remove symbols from current scope
    while c.symbols != null && c.symbols.scope == c.scope_depth {
        c.symbols = c.symbols.next;
    }
    c.scope_depth = c.scope_depth - 1;
}

fn checker_add_symbol(c: *Checker, name: Str, ty: *Type) {
    let sym: *Symbol = arena_alloc(c.arena, 40, 8);
    sym.name = name;
    sym.ty = ty;
    sym.scope = c.scope_depth;
    sym.next = c.symbols;
    c.symbols = sym;
    c.symbol_count = c.symbol_count + 1;
}

fn checker_lookup(c: *Checker, name: Str) -> *Type {
    let sym: *Symbol = c.symbols;
    while sym != null {
        if str_eq(sym.name, name) {
            return sym.ty;
        }
        sym = sym.next;
    }
    return null;
}

fn check_expr(c: *Checker, node: *AstNode) -> *Type {
    if node == null {
        return type_void(c.type_ctx);
    }

    match node.kind {
        AstInt => {
            return type_i64(c.type_ctx);
        }
        AstIdent => {
            let ty: *Type = checker_lookup(c, node.name);
            if ty == null {
                c.errors = c.errors + 1;
                return type_i64(c.type_ctx);
            }
            return ty;
        }
        AstBinOp => {
            let left_ty: *Type = check_expr(c, node.left);
            let right_ty: *Type = check_expr(c, node.right);
            // For now, return left type
            return left_ty;
        }
        AstCall => {
            let fn_ty: *Type = check_expr(c, node.left);
            if fn_ty != null && fn_ty.kind == TyFunc {
                return fn_ty.ret_type;
            }
            return type_i64(c.type_ctx);
        }
        AstField => {
            let obj_ty: *Type = check_expr(c, node.left);
            if obj_ty != null && obj_ty.kind == TyStruct {
                // Look up field
                let field: *TypeField = obj_ty.fields;
                while field != null {
                    if str_eq(field.name, node.name) {
                        return field.ty;
                    }
                    field = field.next;
                }
            }
            return type_i64(c.type_ctx);
        }
        _ => {
            return type_i64(c.type_ctx);
        }
    }
}

fn check_stmt(c: *Checker, node: *AstNode) {
    if node == null {
        return;
    }

    match node.kind {
        AstLet => {
            let init_ty: *Type = check_expr(c, node.right);
            checker_add_symbol(c, node.name, init_ty);
        }
        AstReturn => {
            check_expr(c, node.left);
        }
        AstIf => {
            check_expr(c, node.left);  // condition
            check_stmt(c, node.right);  // then
            check_stmt(c, node.third);  // else
        }
        AstWhile => {
            check_expr(c, node.left);  // condition
            check_stmt(c, node.right);  // body
        }
        AstBlock => {
            checker_push_scope(c);
            let stmt: *AstNode = node.children;
            while stmt != null {
                check_stmt(c, stmt);
                stmt = stmt.next;
            }
            checker_pop_scope(c);
        }
        _ => {
            check_expr(c, node);
        }
    }
}

fn check_fn(c: *Checker, node: *AstNode) {
    checker_push_scope(c);

    // Add parameters to scope
    let param: *AstNode = node.children;  // params list
    while param != null {
        // For now, assume i64 type
        checker_add_symbol(c, param.name, type_i64(c.type_ctx));
        param = param.next;
    }

    // Check function body
    check_stmt(c, node.right);  // body

    checker_pop_scope(c);
}

fn check_module(c: *Checker, module: *AstNode) {
    let decl: *AstNode = module.children;
    while decl != null {
        match decl.kind {
            AstFnDecl => {
                // Add function to scope
                let fn_ty: *Type = arena_alloc(c.arena, 64, 8);
                fn_ty.kind = TyFunc;
                fn_ty.ret_type = type_i64(c.type_ctx);
                checker_add_symbol(c, decl.name, fn_ty);
            }
            AstStructDecl => {
                // Add struct type
                let struct_ty: *Type = arena_alloc(c.arena, 64, 8);
                struct_ty.kind = TyStruct;
                struct_ty.name = decl.name;
                checker_add_symbol(c, decl.name, struct_ty);
            }
            _ => {}
        }
        decl = decl.next;
    }

    // Now check function bodies
    decl = module.children;
    while decl != null {
        if decl.kind == AstFnDecl {
            check_fn(c, decl);
        }
        decl = decl.next;
    }
}

// ============================================================================
// Part 9: IR Types
// ============================================================================

enum IrOpcode {
    IrConst,
    IrLoad,
    IrStore,
    IrAdd,
    IrSub,
    IrMul,
    IrDiv,
    IrMod,
    IrAnd,
    IrOr,
    IrXor,
    IrShl,
    IrShr,
    IrEq,
    IrNe,
    IrLt,
    IrLe,
    IrGt,
    IrGe,
    IrNeg,
    IrNot,
    IrAlloca,
    IrGep,
    IrCall,
    IrRet,
    IrJump,
    IrBranch,
}

// Note: These structs have circular dependencies (*IrFunc, *IrBlock, *IrInstr)
// The C compiler handles this with i64 fallback for pointer types.
// For full self-hosting, these would need forward declarations.

struct IrValue {
    id: i64,
    ty: *Type,
    is_const: bool,
    const_val: i64,
}

// IrBlock needs to be declared before IrInstr for next: *IrBlock
// But IrInstr references IrBlock. This is a circular dependency.
// For now, we rely on pointer-as-i64 fallback for field access.

struct IrBlock {
    name: Str,
    first: *i64,    // Actually *IrInstr - using *i64 for forward ref
    last: *i64,     // Actually *IrInstr
    next: *IrBlock,
}

struct IrFunc {
    name: Str,
    params: **IrValue,
    param_count: i64,
    ret_type: *Type,
    blocks: *IrBlock,
    entry: *IrBlock,
    next: *IrFunc,
}

struct IrInstr {
    opcode: IrOpcode,
    result: *IrValue,
    op1: *IrValue,
    op2: *IrValue,
    // For calls
    callee: *IrFunc,
    args: **IrValue,
    arg_count: i64,
    // For branches
    target: *IrBlock,
    else_target: *IrBlock,
    next: *i64,     // Actually *IrInstr - using *i64 for self-ref
}

struct IrModule {
    arena: *Arena,
    funcs: *IrFunc,
    func_count: i64,
    next_id: i64,
}

// ============================================================================
// Part 10: IR Generator
// ============================================================================

struct IrGen {
    module: *IrModule,
    arena: *Arena,
    type_ctx: *TypeContext,
    current_func: *IrFunc,
    current_block: *IrBlock,
    // Symbol table for IR values
    symbols: *IrSymbol,
}

struct IrSymbol {
    name: Str,
    value: *IrValue,
    next: *IrSymbol,
}

fn irgen_init(g: *IrGen, arena: *Arena, type_ctx: *TypeContext) {
    g.arena = arena;
    g.type_ctx = type_ctx;
    g.module = arena_alloc(arena, 48, 8);
    g.module.arena = arena;
    g.module.funcs = null;
    g.module.func_count = 0;
    g.module.next_id = 1;
    g.current_func = null;
    g.current_block = null;
    g.symbols = null;
}

fn irgen_new_value(g: *IrGen, ty: *Type) -> *IrValue {
    let v: *IrValue = arena_alloc(g.arena, 32, 8);
    v.id = g.module.next_id;
    g.module.next_id = g.module.next_id + 1;
    v.ty = ty;
    v.is_const = false;
    return v;
}

fn irgen_const(g: *IrGen, val: i64) -> *IrValue {
    let v: *IrValue = irgen_new_value(g, type_i64(g.type_ctx));
    v.is_const = true;
    v.const_val = val;
    return v;
}

fn irgen_new_block(g: *IrGen, name: Str) -> *IrBlock {
    let b: *IrBlock = arena_alloc(g.arena, 40, 8);
    b.name = name;
    b.first = null;
    b.last = null;
    b.next = null;
    return b;
}

fn irgen_emit(g: *IrGen, instr: *IrInstr) {
    if g.current_block == null {
        return;
    }
    if g.current_block.first == null {
        g.current_block.first = instr;
    } else {
        g.current_block.last.next = instr;
    }
    g.current_block.last = instr;
}

fn irgen_add_symbol(g: *IrGen, name: Str, value: *IrValue) {
    let sym: *IrSymbol = arena_alloc(g.arena, 24, 8);
    sym.name = name;
    sym.value = value;
    sym.next = g.symbols;
    g.symbols = sym;
}

fn irgen_lookup(g: *IrGen, name: Str) -> *IrValue {
    let sym: *IrSymbol = g.symbols;
    while sym != null {
        if str_eq(sym.name, name) {
            return sym.value;
        }
        sym = sym.next;
    }
    return null;
}

fn irgen_lookup_func(g: *IrGen, name: Str) -> *IrFunc {
    let func: *IrFunc = g.module.funcs;
    while func != null {
        if str_eq(func.name, name) {
            return func;
        }
        func = func.next;
    }
    return null;
}

fn irgen_expr(g: *IrGen, node: *AstNode) -> *IrValue {
    if node == null {
        return irgen_const(g, 0);
    }

    match node.kind {
        AstInt => {
            return irgen_const(g, node.int_value);
        }
        AstIdent => {
            let v: *IrValue = irgen_lookup(g, node.name);
            if v != null {
                // Load from alloca
                let instr: *IrInstr = arena_alloc(g.arena, 80, 8);
                instr.opcode = IrLoad;
                instr.result = irgen_new_value(g, type_i64(g.type_ctx));
                instr.op1 = v;
                irgen_emit(g, instr);
                return instr.result;
            }
            return irgen_const(g, 0);
        }
        AstBinOp => {
            let left: *IrValue = irgen_expr(g, node.left);
            let right: *IrValue = irgen_expr(g, node.right);
            let instr: *IrInstr = arena_alloc(g.arena, 80, 8);

            match node.op {
                TokPlus => { instr.opcode = IrAdd; }
                TokMinus => { instr.opcode = IrSub; }
                TokStar => { instr.opcode = IrMul; }
                TokSlash => { instr.opcode = IrDiv; }
                TokPercent => { instr.opcode = IrMod; }
                TokEqEq => { instr.opcode = IrEq; }
                TokBangEq => { instr.opcode = IrNe; }
                TokLt => { instr.opcode = IrLt; }
                TokGt => { instr.opcode = IrGt; }
                TokLtEq => { instr.opcode = IrLe; }
                TokGtEq => { instr.opcode = IrGe; }
                TokAmp => { instr.opcode = IrAnd; }
                TokPipe => { instr.opcode = IrOr; }
                TokCaret => { instr.opcode = IrXor; }
                _ => { instr.opcode = IrAdd; }
            }

            instr.result = irgen_new_value(g, type_i64(g.type_ctx));
            instr.op1 = left;
            instr.op2 = right;
            irgen_emit(g, instr);
            return instr.result;
        }
        AstCall => {
            // Get callee function name
            let callee_name: Str = node.left.name;
            let callee: *IrFunc = irgen_lookup_func(g, callee_name);

            // Count arguments
            let arg_count: i64 = 0;
            let arg_node: *AstNode = node.children;
            while arg_node != null {
                arg_count = arg_count + 1;
                arg_node = arg_node.next;
            }

            // Allocate args array
            let args: **IrValue = null;
            if arg_count > 0 {
                args = arena_alloc(g.arena, arg_count * 8, 8);
                let i: i64 = 0;
                arg_node = node.children;
                while arg_node != null {
                    args[i] = irgen_expr(g, arg_node);
                    i = i + 1;
                    arg_node = arg_node.next;
                }
            }

            // Create call instruction
            let instr: *IrInstr = arena_alloc(g.arena, 80, 8);
            instr.opcode = IrCall;
            instr.result = irgen_new_value(g, type_i64(g.type_ctx));
            instr.callee = callee;
            instr.args = args;
            instr.arg_count = arg_count;
            irgen_emit(g, instr);
            return instr.result;
        }
        _ => {
            return irgen_const(g, 0);
        }
    }
}

fn irgen_stmt(g: *IrGen, node: *AstNode) {
    if node == null {
        return;
    }

    match node.kind {
        AstLet => {
            // Allocate stack space
            let alloca: *IrInstr = arena_alloc(g.arena, 80, 8);
            alloca.opcode = IrAlloca;
            alloca.result = irgen_new_value(g, type_ptr(g.type_ctx, type_i64(g.type_ctx)));
            irgen_emit(g, alloca);

            // Store initial value
            if node.right != null {
                let init: *IrValue = irgen_expr(g, node.right);
                let store: *IrInstr = arena_alloc(g.arena, 80, 8);
                store.opcode = IrStore;
                store.op1 = alloca.result;
                store.op2 = init;
                irgen_emit(g, store);
            }

            irgen_add_symbol(g, node.name, alloca.result);
        }
        AstReturn => {
            let val: *IrValue = irgen_expr(g, node.left);
            let ret: *IrInstr = arena_alloc(g.arena, 80, 8);
            ret.opcode = IrRet;
            ret.op1 = val;
            irgen_emit(g, ret);
        }
        AstIf => {
            let cond: *IrValue = irgen_expr(g, node.left);
            let then_block: *IrBlock = irgen_new_block(g, node.name);  // reuse name field
            let else_block: *IrBlock = irgen_new_block(g, node.name);
            let merge_block: *IrBlock = irgen_new_block(g, node.name);

            // Branch instruction
            let br: *IrInstr = arena_alloc(g.arena, 80, 8);
            br.opcode = IrBranch;
            br.op1 = cond;
            br.target = then_block;
            br.else_target = else_block;
            irgen_emit(g, br);

            // Then block
            g.current_block = then_block;
            irgen_stmt(g, node.right);
            let jmp1: *IrInstr = arena_alloc(g.arena, 80, 8);
            jmp1.opcode = IrJump;
            jmp1.target = merge_block;
            irgen_emit(g, jmp1);

            // Else block
            g.current_block = else_block;
            if node.third != null {
                irgen_stmt(g, node.third);
            }
            let jmp2: *IrInstr = arena_alloc(g.arena, 80, 8);
            jmp2.opcode = IrJump;
            jmp2.target = merge_block;
            irgen_emit(g, jmp2);

            g.current_block = merge_block;
        }
        AstWhile => {
            let cond_block: *IrBlock = irgen_new_block(g, node.name);
            let body_block: *IrBlock = irgen_new_block(g, node.name);
            let exit_block: *IrBlock = irgen_new_block(g, node.name);

            // Jump to condition
            let jmp: *IrInstr = arena_alloc(g.arena, 80, 8);
            jmp.opcode = IrJump;
            jmp.target = cond_block;
            irgen_emit(g, jmp);

            // Condition block
            g.current_block = cond_block;
            let cond: *IrValue = irgen_expr(g, node.left);
            let br: *IrInstr = arena_alloc(g.arena, 80, 8);
            br.opcode = IrBranch;
            br.op1 = cond;
            br.target = body_block;
            br.else_target = exit_block;
            irgen_emit(g, br);

            // Body block
            g.current_block = body_block;
            irgen_stmt(g, node.right);
            let back: *IrInstr = arena_alloc(g.arena, 80, 8);
            back.opcode = IrJump;
            back.target = cond_block;
            irgen_emit(g, back);

            g.current_block = exit_block;
        }
        AstBlock => {
            let stmt: *AstNode = node.children;
            while stmt != null {
                irgen_stmt(g, stmt);
                stmt = stmt.next;
            }
        }
        _ => {
            irgen_expr(g, node);
        }
    }
}

fn irgen_func(g: *IrGen, node: *AstNode) {
    let func: *IrFunc = arena_alloc(g.arena, 56, 8);
    func.name = node.name;
    func.param_count = 0;
    func.blocks = null;
    func.next = g.module.funcs;
    g.module.funcs = func;
    g.module.func_count = g.module.func_count + 1;

    g.current_func = func;

    // Create entry block
    let entry: *IrBlock = irgen_new_block(g, node.name);
    func.entry = entry;
    func.blocks = entry;
    g.current_block = entry;

    // Generate body
    irgen_stmt(g, node.right);

    g.current_func = null;
    g.current_block = null;
}

fn irgen_module(g: *IrGen, module: *AstNode) {
    let decl: *AstNode = module.children;
    while decl != null {
        if decl.kind == AstFnDecl {
            irgen_func(g, decl);
        }
        decl = decl.next;
    }
}

// ============================================================================
// Part 11: x64 Code Generator
// ============================================================================

enum X64Reg {
    RAX, RCX, RDX, RBX, RSP, RBP, RSI, RDI,
    R8, R9, R10, R11, R12, R13, R14, R15,
}

struct X64Gen {
    arena: *Arena,
    code: *u8,
    code_size: i64,
    code_capacity: i64,
    // Register allocation
    reg_alloc: *i64,
    stack_offset: i64,
    // Fixups for jumps
    fixups: *X64Fixup,
    fixup_count: i64,
}

struct X64Fixup {
    offset: i64,
    target_block: *IrBlock,
    next: *X64Fixup,
}

fn x64_init(g: *X64Gen, arena: *Arena) {
    g.arena = arena;
    g.code_capacity = 65536;
    g.code = arena_alloc(arena, g.code_capacity, 16);
    g.code_size = 0;
    g.stack_offset = 0;
    g.fixups = null;
    g.fixup_count = 0;
}

fn x64_emit_byte(g: *X64Gen, b: u8) {
    if g.code_size < g.code_capacity {
        g.code[g.code_size] = b;
        g.code_size = g.code_size + 1;
    }
}

fn x64_emit_dword(g: *X64Gen, val: i32) {
    x64_emit_byte(g, val & 255);
    x64_emit_byte(g, (val >> 8) & 255);
    x64_emit_byte(g, (val >> 16) & 255);
    x64_emit_byte(g, (val >> 24) & 255);
}

fn x64_emit_qword(g: *X64Gen, val: i64) {
    x64_emit_dword(g, val & 0xFFFFFFFF);
    x64_emit_dword(g, (val >> 32) & 0xFFFFFFFF);
}

// REX prefix
fn x64_rex(g: *X64Gen, w: bool, r: bool, x: bool, b: bool) {
    let rex: u8 = 0x40;
    if w { rex = rex | 0x08; }
    if r { rex = rex | 0x04; }
    if x { rex = rex | 0x02; }
    if b { rex = rex | 0x01; }
    x64_emit_byte(g, rex);
}

// ModRM byte
fn x64_modrm(mod: u8, reg: u8, rm: u8) -> u8 {
    return (mod << 6) | ((reg & 7) << 3) | (rm & 7);
}

// mov reg, imm64
fn x64_mov_reg_imm64(g: *X64Gen, reg: X64Reg, imm: i64) {
    x64_rex(g, true, false, false, reg >= R8);
    x64_emit_byte(g, 0xB8 + (reg & 7));
    x64_emit_qword(g, imm);
}

// mov reg, [rbp+offset]
fn x64_mov_reg_rbp_offset(g: *X64Gen, reg: X64Reg, offset: i32) {
    x64_rex(g, true, reg >= R8, false, false);
    x64_emit_byte(g, 0x8B);
    x64_emit_byte(g, x64_modrm(2, reg, RBP));
    x64_emit_dword(g, offset);
}

// mov [rbp+offset], reg
fn x64_mov_rbp_offset_reg(g: *X64Gen, offset: i32, reg: X64Reg) {
    x64_rex(g, true, reg >= R8, false, false);
    x64_emit_byte(g, 0x89);
    x64_emit_byte(g, x64_modrm(2, reg, RBP));
    x64_emit_dword(g, offset);
}

// add rax, rcx
fn x64_add_rax_rcx(g: *X64Gen) {
    x64_rex(g, true, false, false, false);
    x64_emit_byte(g, 0x01);
    x64_emit_byte(g, x64_modrm(3, RCX, RAX));
}

// sub rax, rcx
fn x64_sub_rax_rcx(g: *X64Gen) {
    x64_rex(g, true, false, false, false);
    x64_emit_byte(g, 0x29);
    x64_emit_byte(g, x64_modrm(3, RCX, RAX));
}

// push rbp
fn x64_push_rbp(g: *X64Gen) {
    x64_emit_byte(g, 0x55);
}

// pop rbp
fn x64_pop_rbp(g: *X64Gen) {
    x64_emit_byte(g, 0x5D);
}

// mov rbp, rsp
fn x64_mov_rbp_rsp(g: *X64Gen) {
    x64_rex(g, true, false, false, false);
    x64_emit_byte(g, 0x89);
    x64_emit_byte(g, x64_modrm(3, RSP, RBP));
}

// sub rsp, imm32
fn x64_sub_rsp_imm(g: *X64Gen, imm: i32) {
    x64_rex(g, true, false, false, false);
    x64_emit_byte(g, 0x81);
    x64_emit_byte(g, x64_modrm(3, 5, RSP));
    x64_emit_dword(g, imm);
}

// add rsp, imm32
fn x64_add_rsp_imm(g: *X64Gen, imm: i32) {
    x64_rex(g, true, false, false, false);
    x64_emit_byte(g, 0x81);
    x64_emit_byte(g, x64_modrm(3, 0, RSP));
    x64_emit_dword(g, imm);
}

// ret
fn x64_ret(g: *X64Gen) {
    x64_emit_byte(g, 0xC3);
}

// cmp rax, rcx
fn x64_cmp_rax_rcx(g: *X64Gen) {
    x64_rex(g, true, false, false, false);
    x64_emit_byte(g, 0x39);
    x64_emit_byte(g, x64_modrm(3, RCX, RAX));
}

// sete al
fn x64_sete_al(g: *X64Gen) {
    x64_emit_byte(g, 0x0F);
    x64_emit_byte(g, 0x94);
    x64_emit_byte(g, x64_modrm(3, 0, RAX));
}

// setl al
fn x64_setl_al(g: *X64Gen) {
    x64_emit_byte(g, 0x0F);
    x64_emit_byte(g, 0x9C);
    x64_emit_byte(g, x64_modrm(3, 0, RAX));
}

// movzx rax, al
fn x64_movzx_rax_al(g: *X64Gen) {
    x64_rex(g, true, false, false, false);
    x64_emit_byte(g, 0x0F);
    x64_emit_byte(g, 0xB6);
    x64_emit_byte(g, x64_modrm(3, RAX, RAX));
}

fn x64_gen_prologue(g: *X64Gen, stack_size: i32) {
    x64_push_rbp(g);
    x64_mov_rbp_rsp(g);
    if stack_size > 0 {
        x64_sub_rsp_imm(g, stack_size);
    }
}

fn x64_gen_epilogue(g: *X64Gen, stack_size: i32) {
    if stack_size > 0 {
        x64_add_rsp_imm(g, stack_size);
    }
    x64_pop_rbp(g);
    x64_ret(g);
}

fn x64_gen_instr(g: *X64Gen, instr: *IrInstr) {
    match instr.opcode {
        IrConst => {
            // Result is a constant, handle when used
        }
        IrLoad => {
            // mov rax, [rbp+offset]
            // For simplicity, use fixed offsets based on value id
            let offset: i32 = (instr.op1.id * -8);
            x64_mov_reg_rbp_offset(g, RAX, offset);
        }
        IrStore => {
            // Load value to RAX first
            if instr.op2.is_const {
                x64_mov_reg_imm64(g, RAX, instr.op2.const_val);
            }
            // mov [rbp+offset], rax
            let offset: i32 = (instr.op1.id * -8);
            x64_mov_rbp_offset_reg(g, offset, RAX);
        }
        IrAdd => {
            // Load operands
            if instr.op1.is_const {
                x64_mov_reg_imm64(g, RAX, instr.op1.const_val);
            }
            if instr.op2.is_const {
                x64_mov_reg_imm64(g, RCX, instr.op2.const_val);
            }
            x64_add_rax_rcx(g);
        }
        IrSub => {
            if instr.op1.is_const {
                x64_mov_reg_imm64(g, RAX, instr.op1.const_val);
            }
            if instr.op2.is_const {
                x64_mov_reg_imm64(g, RCX, instr.op2.const_val);
            }
            x64_sub_rax_rcx(g);
        }
        IrEq => {
            if instr.op1.is_const {
                x64_mov_reg_imm64(g, RAX, instr.op1.const_val);
            }
            if instr.op2.is_const {
                x64_mov_reg_imm64(g, RCX, instr.op2.const_val);
            }
            x64_cmp_rax_rcx(g);
            x64_sete_al(g);
            x64_movzx_rax_al(g);
        }
        IrLt => {
            if instr.op1.is_const {
                x64_mov_reg_imm64(g, RAX, instr.op1.const_val);
            }
            if instr.op2.is_const {
                x64_mov_reg_imm64(g, RCX, instr.op2.const_val);
            }
            x64_cmp_rax_rcx(g);
            x64_setl_al(g);
            x64_movzx_rax_al(g);
        }
        IrRet => {
            if instr.op1 != null && instr.op1.is_const {
                x64_mov_reg_imm64(g, RAX, instr.op1.const_val);
            }
            x64_gen_epilogue(g, 64);  // Assume 64 bytes stack
        }
        _ => {
            // Other instructions not yet implemented
        }
    }
}

fn x64_gen_block(g: *X64Gen, block: *IrBlock) {
    let instr: *IrInstr = block.first;
    while instr != null {
        x64_gen_instr(g, instr);
        instr = instr.next;
    }
}

fn x64_gen_func(g: *X64Gen, func: *IrFunc) {
    x64_gen_prologue(g, 64);

    let block: *IrBlock = func.blocks;
    while block != null {
        x64_gen_block(g, block);
        block = block.next;
    }
}

fn x64_gen_module(g: *X64Gen, module: *IrModule) {
    let func: *IrFunc = module.funcs;
    while func != null {
        x64_gen_func(g, func);
        func = func.next;
    }
}

// ============================================================================
// Part 12: ELF Writer
// ============================================================================

struct ElfWriter {
    arena: *Arena,
    output: *u8,
    output_size: i64,
    output_capacity: i64,
}

fn elf_init(w: *ElfWriter, arena: *Arena) {
    w.arena = arena;
    w.output_capacity = 131072;
    w.output = arena_alloc(arena, w.output_capacity, 16);
    w.output_size = 0;
}

fn elf_emit_byte(w: *ElfWriter, b: u8) {
    if w.output_size < w.output_capacity {
        w.output[w.output_size] = b;
        w.output_size = w.output_size + 1;
    }
}

fn elf_emit_half(w: *ElfWriter, val: i16) {
    elf_emit_byte(w, val & 255);
    elf_emit_byte(w, (val >> 8) & 255);
}

fn elf_emit_word(w: *ElfWriter, val: i32) {
    elf_emit_byte(w, val & 255);
    elf_emit_byte(w, (val >> 8) & 255);
    elf_emit_byte(w, (val >> 16) & 255);
    elf_emit_byte(w, (val >> 24) & 255);
}

fn elf_emit_xword(w: *ElfWriter, val: i64) {
    elf_emit_word(w, val & 0xFFFFFFFF);
    elf_emit_word(w, (val >> 32) & 0xFFFFFFFF);
}

fn elf_write_header(w: *ElfWriter, entry_point: i64, phdr_offset: i64, phdr_count: i16) {
    // ELF magic
    elf_emit_byte(w, 0x7F);
    elf_emit_byte(w, 0x45);  // E
    elf_emit_byte(w, 0x4C);  // L
    elf_emit_byte(w, 0x46);  // F

    // ELF class (64-bit)
    elf_emit_byte(w, 2);
    // Data encoding (little endian)
    elf_emit_byte(w, 1);
    // ELF version
    elf_emit_byte(w, 1);
    // OS ABI
    elf_emit_byte(w, 0);

    // Padding (8 bytes)
    let i: i64 = 0;
    while i < 8 {
        elf_emit_byte(w, 0);
        i = i + 1;
    }

    // Type (executable)
    elf_emit_half(w, 2);
    // Machine (x86-64)
    elf_emit_half(w, 62);
    // Version
    elf_emit_word(w, 1);
    // Entry point
    elf_emit_xword(w, entry_point);
    // Program header offset
    elf_emit_xword(w, phdr_offset);
    // Section header offset (0 for no sections)
    elf_emit_xword(w, 0);
    // Flags
    elf_emit_word(w, 0);
    // ELF header size
    elf_emit_half(w, 64);
    // Program header entry size
    elf_emit_half(w, 56);
    // Program header count
    elf_emit_half(w, phdr_count);
    // Section header entry size
    elf_emit_half(w, 64);
    // Section header count
    elf_emit_half(w, 0);
    // Section name string table index
    elf_emit_half(w, 0);
}

fn elf_write_phdr(w: *ElfWriter, vaddr: i64, file_offset: i64, file_size: i64, mem_size: i64, flags: i32) {
    // Type (PT_LOAD)
    elf_emit_word(w, 1);
    // Flags (PF_R | PF_X)
    elf_emit_word(w, flags);
    // File offset
    elf_emit_xword(w, file_offset);
    // Virtual address
    elf_emit_xword(w, vaddr);
    // Physical address
    elf_emit_xword(w, vaddr);
    // File size
    elf_emit_xword(w, file_size);
    // Memory size
    elf_emit_xword(w, mem_size);
    // Alignment
    elf_emit_xword(w, 4096);
}

fn elf_write_executable(w: *ElfWriter, code: *u8, code_size: i64) {
    // Base addresses
    let base_addr: i64 = 0x400000;
    let header_size: i64 = 64 + 56;  // ELF header + 1 program header
    let text_offset: i64 = 4096;  // Align to page
    let entry_point: i64 = base_addr + text_offset;

    // Write ELF header
    elf_write_header(w, entry_point, 64, 1);

    // Write program header
    elf_write_phdr(w, base_addr + text_offset, text_offset, code_size, code_size, 5);

    // Pad to text offset
    while w.output_size < text_offset {
        elf_emit_byte(w, 0);
    }

    // Write code
    let i: i64 = 0;
    while i < code_size {
        elf_emit_byte(w, code[i]);
        i = i + 1;
    }
}

// ============================================================================
// Part 13: Entry Point
// ============================================================================

fn main() -> i32 {
    // Test struct creation and field access
    let v: Vint = vint_new(42);
    if v.value != 42 {
        return 1;  // vint_new failed
    }

    // Test vint_is_void
    if vint_is_void(v) {
        return 2;  // should not be void
    }

    // Test vint_void
    let void_v: Vint = vint_void();
    if !vint_is_void(void_v) {
        return 3;  // should be void
    }

    // Test while loop
    let counter: i64 = 0;
    while counter < 5 {
        counter = counter + 1;
    }
    if counter != 5 {
        return 4;  // loop failed
    }

    // Test lexer component
    // Note: This requires arena allocation which needs memory setup
    // For now, we verify the type system works

    // All tests passed
    return 42;
}
